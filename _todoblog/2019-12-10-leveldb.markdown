---
layout: post
title: Database Storage Structure
date: 2019-12-10 11:21
categories:
  - ALGO
  - Database
typora-root-url: ../../yummyliu.github.io
---
* TOC
{:toc}
TransactionManager/LockManager/LogManager/AccessMethod are the four importance component in transactional storage engine. AccessMethod means the data organization structure, such as Btree/LSM-tree. 

Btree's appearance is based on HDD disk；nowadays, there are more and more difference storage medium, so that the research of new accessmethod is going on. In this article, I want to summarize my knowledge on this question——Database AccessMethod. (My English is so poor, but I still insist on writing on English to practise it.)

this article include three section, firstly, I introduce the RUM conjecture of accessmethod. secondly, I review the classic accessmethod——Btree. At last, I share my study on the new(no that new, since it is came up in 1996) and popular access method——LSM-tree. 

# RUM conjecture

> **RUM conjecture**
>
> *When designing access methods we set an upper bound for two of the RUM overheads, this implies a hard lower bound for the third overhead which cannot be further reduced*

![img](/_todoblog/1212-rum.png)

like the CAP theory for distribution consensus, RUM conjecture is the triangle for access method. it mean that we can not have a perfect access method whcih satisfy Read Optimized/Update Optimized/MemoryOptimized. we try our best to only satify two of the three with sacrificed the other one.

When we design a DB storage structure, there are three amplification we need to think(below image).



![image-20191213172335893](/image/1212-storage.png)

To optimize write amplification, we can use differential data structure to consolidate many update into one I/O, and avoid the cost of data reorganization. but it slows down read and has space waste.G

To optimize read amplificatioin, we can use special physical index for appropriate workload, but it brings the wirte and space waste since there are multiple data copies.

Based on this conjecture, we can rethink Btree and LSM-tree.

# Btree

let's review btree. BTREE is self-**B**alancing **TREE**. Comparing to BST/AVL-tree/Red-Black-tree, it is a **disk** balance tree. 

![image-20191215101830900](/image/1212-BBB.png)

Generally, we mean B+-tree when we say Btree. assuming that table size is N, which means leafnodes has **N** records；we assume that the depth of B+-tree does not count leaflevel and one page has **B** record; so the depth of Btree is $log_{B}N/B$, it is smaller than BST, so that we can minimize that I/O counts.

<=> $N = B^{depth+1}$

<=> $N/B = B^{depth}$

<=>$depth = log_{B}N/B$

Furthermore, when read a record of Btree, it needs to read all node in the path. so, read amplication of Btree equals to depth. And write a record in leafnode, it needs to write out the whole page, so write amplificatioin of Btree is B.

Btree is used in all tranditional DBMS, like InnoDB, PostgreSQL. now, there are many special storage engine, like LevelDB/RocksDB. It use a different structure——LSM-tree, which claims that has better write performance than Btree and with no so bad read performance. let's check it out.

# LSM-tree

LSM-tree(Log Struct Merge tree) is a concept rather than a concrete structure. The log concept is borrowed from Log Structured File System, not from database write ahead log. Tree in LSM-tree can be replaced by other structure, like map. The nut of LSM-tree is Merge. LSM tree takes full advantage of multi-level storage to buffer writes, so that it has good write performance.

> Log is borrowed, Tree can be replaced, Merge is the king.

Therefore, understanding how merge is done is the key to understand LSM-tree.LSM-tree is compose of two or more tree-like components, which distribute from small, expensive and higher performing medium to larger, cheap and less performant medium.

Nowadays, there are many..

![image-20191215215655435](/image/1212-cass.png)

![image-20191215221028911](/image/1212-inno.png)



![image-20191213183201768](/image/1212-level.png)

Upstream level

when search a LSM-tree, we first search level-0, then level-1, and so on. 

when insert an entry, we just always insert into level-0 and return. so, we have a good insert performance, however, doing an insert into btree with bufferpool also can return without IO, but bufferpool maybe miss that need an extra IO to load page. 

For the cause of size-limited memory, level0 is limited, so that LSM-tree has an importance process: merge(compaction). when upstream level reach size-threshold, it is time to approach a compaction:

1. read a block B from downstream
2. read entries from upstream, and insert into B
3. upstream's size get reduced, and create new merged downstream block.

it need to know that new merged block is written to new disk position, so that the old block can be used in recovery. 

Sized-tiered Compaction Strategy

Level-based compaction strategy





Database has  N records， means that the last level has N records。it assume that we have $d$ levels, the first level has B record and every compaction has growth factor——k, so that

<=>$B*k^d = N$

<=>$d=log_{k}^{N/B}$

![image-20191213172406015](/image/1212-btr-lsm.png)

| Data Structure       | Write Amplification | Read Amplification |
| -------------------- | ------------------- | ------------------ |
| B+ tree              | Θ($B$)              | $O(log_{B}N/B)$    |
| Level-Based LSM-tree | Θ($klog_{k}{N/B}$)  | Θ((log^2N/B)/logk) |



![image-20191214163244389](/../Library/Application Support/typora-user-images/image-20191214163244389.png)

bloom filter optimize read IO，but only work in point query，we can use Prefix bloom filter that work for `like %`。

> there are another algo：Succinct Range Filter which like a trie。
>
> Cuckoo Filter

![image-20191214165444186](/../Library/Application Support/typora-user-images/image-20191214165444186.png)

![image-20191214165250051](/../Library/Application Support/typora-user-images/image-20191214165250051.png)



![image-20191214165652461](/../Library/Application Support/typora-user-images/image-20191214165652461.png)



Problem of compaction:

+ write amplification
  + sys jitter (CPU IO)
  + SSD wear out
+ Invalid block cache/page cache ?
+ compaction rate is a problem，Too fast bring write amplification，to slow bring read amplification and space amplification。



compaction:

1. sorting
2. garbage collection



optimization of compaction：

+ pipelined compaction，try my best to make every procedure in pipeline cost similar time；and in multi-core sys，may result in low CPU cache performance。 
+ FPGA
+ Wisckey: separate key and value, key use for sorting， value use for garbage collection
+ 



[lsm1](https://www.slideshare.net/ssuser7e134a/log-structured-merge-tree)