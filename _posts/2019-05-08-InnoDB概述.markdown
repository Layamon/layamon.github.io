---
layout: post
title: InnoDB初见——Buffer与Log
date: 2019-05-08 17:06
header-img: "img/head.jpg"
categories: jekyll update
tags:
  - InnoDB
typora-root-url: ../../yummyliu.github.io
---

* TOC
{:toc}
# InnoDB与MySQL

MySQL下面可以支持多种存储引擎，InnoDB是默认的那个。类似PgSQL的多进程结构，MySQL是多线程结构，其中有如下的线程角色

- User thread：每个链接一个线程；
- Master thread：整体活动的调度；比如flush，purge，checkpoint，insert buffer merge等。
- IO threads
  - read threads：多线程的预读
  - write threads：多线程的后台写
  - Insert Buffer thread：Insert Buffer合并
  - log thread：刷新log
- Purge threads：周期性执行的垃圾回收
  - 清理index中的废弃值
  - 清理表中被标记为`deleted`的记录。
  - 清理undo日志中的历史记录（rollback segment）。
- ### 死锁检测/Page cleaner (flush)/FTS, Statistics, Monitor, Drop table, Dump
  
  buffer pool等任务线程

InnoDB承担了MySQL作为一个RDBMS的存储部分的工作，比如Lock管理，访问方法，日志管理以及缓冲区管理。由于缓冲区和日志一般都是联动了，这里先从这两个部分开始了解。

# InnoDB缓冲区管理

在InnoDB中，有如下一些缓冲区；大类上和PgSQL相似都有一个放数据页的BufferPool，和一个放日志记录的LogBuffer。在CHECKPOINT的调度下，进行BufferPool刷盘；每次事务commit进行Log记录刷盘(这里可能不太准确，存在group commit)。除了这两个之外，在MySQL中，为了解决特定的问题，还有一些其他的Buffer；比如，Change Buffer和DoubleWrite Buffer。

> 另外，还有存储元数据目录的`innodb_additional_mem_pool_size`；默认8MB，如果不够就会动态申请，然后再日志中写warning。


## Change Buffer

当二级索引的块不在缓存中时，允许将相应更改缓存起来。包括三类更改：insert/delete/purge。

当changeBuffer满了，会读取相应的页，按照changeBuffer进行merge。

1. 随机选择changeBuffer中一个随机页。
2. 随机打开该页中的一个cursor。
3. 按照该cursor，读取之后的至多8个页。
4. 异步发起IO请求；当读取完成后，调用回调函数，执行相应的change。

## Buffer Pool

存放表和索引的数据，由`innodb_buffer_pool_size`设置，默认是128MB；推荐配置为系统物理内存的80%。

### CHECKPOINT

CHECKPOINT在DBMS都是同一个概念，其为redo日志中的一条记录，其表示在该记录之前的数据页的更改已经从缓冲区写入磁盘了。

> 有两种类型的CHECKPOINT：
>
> **sharp checkpoint**:
>
> 只将commited的事务修改的页进行刷盘，并且记下最新Commited的事务的LSN。这样恢复的时候，redo日志从CHECKPOINT发生的LSN开始恢复即可。由于所有刷盘的数据都是在同一个点(CHECKPOINT LSN)之后，所以称之为sharp。
>
> **fuzzy checkpoint:**
>
> 如果脏页滞留到一定时间，就可能会刷盘。这种方式在日志中写下两个LSN：CHECKPOINT start和CHECKPOINT end。当恢复的时候，还是从CHECKPOINT start开始恢复。
>
> ——[Gray and Reuter’s classic text on transaction processing](https://www.amazon.com/gp/product/1558601902/?tag=xaprb-20)

在InnoDB中，除了shutdown的时候，正常时候都是fuzzy CHECKPOINT。刷盘前，能够多次修改，这样省去了很多IO。

池中的页由三个list维护，分别是：

+ free_list：可用的页
+ LRU_list：最近使用的页
+ flush_list：按照LSN的顺序组织的脏页（即，最近修改的页）。

由于buffer池是有限的，不能只是等满了才进行页换出（LRU_list）；所以，InnoDB会持续地进行CHECKPOINT，这里主要和flush_list相关。基于flush_list的换出就是选择最早更改的脏页(LSN)进行换出。因此，InnoDB中的换出有两种情况。

- BufferPool满了之后，基于LRU_list，进行页面置换。
- 主动进行刷盘，基于flush_list，其中按照修改的先后顺序排列。

> 为了避免将热数据换出，所以选择了最早更改的脏页。另外，由于事务日志（即，redo/wal日志）是固定大小的，因此，redo日志是循环使用的。当最早的日志记录相应的页一直没有刷盘，如果此时发生了日志重用，那么更改就没有持久化(违反D)；因此，当这种情况发生时，InnoDB需要夯住，进行刷盘（同样这也是为什么选择最早更改的脏页的一个原因）。
>

综上，当InnoDB执行fuzzy CHECKPOINT的时候，其会找到flush_list中的最早更改的脏页的LSN，将其作为CHECKPOINT的start，写入事务日志头中(参见源码：`log_checkpoint_margin`和`log_checkpoint`)。

而当InnoDB停机时，做法就是sharp checkpoint。首先，停止数据更新；然后，将脏页刷盘；最后，将当前的LSN写入事务日志头中。

> 另外，在Percona版本的XtraDB中，提供了一种基于代价的 adaptive CHECKPOINT；以及InnoDB后来也有了[adaptive flushing]([http://dimitrik.free.fr/blog/archives/2010/07/mysql-performance-innodb-io-capacity-flushing.html](http://dimitrik.free.fr/blog/archives/2010/07/mysql-performance-innodb-io-capacity-flushing.html))。

## Log Buffer

InnoDB的表发生变更的时候，首先将变更存储在Log Buffer中，然后写入到Redo日志中。其由`innodb_log_buffer_size`设置，默认16MB；当大事务中的insert/update/delete比较多时，将提高该参数可以减少磁盘IO；通过观察系统参数`innodb_log_waits`，可以得知是否需要调大LogBuffer。

```sql
SELECT name, subsystem, status FROM INFORMATION_SCHEMA.INNODB_METRICS;
```

## Doublewrite Buffer(disk)

InnoDB的页大小是16k，但是OS每次是按照4K写入，因此可能存在16K部分写的情况下，系统crash了。为了避免这一问题，设计了doublewrite_buffer。

dwbuffer可以看做是存在于**系统表空间**中的一个短期的日志文件，它包含了100个页。当InnoDB刷页时，会先将页**顺序**写入到dwbuffer中，并将dwbuffer刷盘；然后，将页刷到真正的数据文件中。

当recovery时，InnoDB检查dwbuffer中页和其本来位置的页的内容；如果dwbuffer中的页是不一致的，那么丢弃该页；如果表中的页是不一致的，那么从dwbuffer中恢复。

性能上，尽管每次写页的时候需要写两次；但是由于将dwbuffer的写是顺序的，并且不会每个page调用一次fsync，而是一起fsync；整体性能比原来损失经验值是5%。

> 如果你不在乎数据丢失，或者OS级别保证了不会有部分写，那么可以`innodb_doublewrite=0` 关闭double write。

# InnoDB日志管理

数据库日志是保证事务的ACID的重要机制，按照数据恢复的一般算法**ARIES**如下，数据库的日志一般有两种：REDO和UNDO；另外，在MySQL层，还有一个BinLog，但其不属于InnoDB。

> ARIES
>
> - Write ahead logging
> - Rpeating history during Redo
> - Logging change during Undo

日志一般分为三种：

- 纯物理日志：记录数据页的物理字节位置和内容。
- 纯逻辑日志：记录更改的语句。
- 物理的逻辑日志（Physiological Log）：记录物理页中更改的逻辑，这里的逻辑不是SQL逻辑，而是物理页中的变更操作。

现代DBMS中，一般采用的是Physiological方式。其日志体积更小，恢复更快，并且解决了逻辑日志的非幂等性。

> **逻辑日志的非幂等性**
>
> 比如，逻辑日志中有一个insert a in A，其需要更新数据和索引页。但是crash的时候，可能只更新了data，没有更新index。

## MTR

以向一级索引中，插入一条元组为例；如果有相同健值的元组，那么存在两种情况：

1. 该元组已经被一个commited的事务标记删除了
2. 返回主键冲突的异常

对于第一种情况，当前的insert事务需要针对标记删除的元组写一个undolog。

> dict_index_t->n_uniq：在dict_index_t->n_fields中，从前向后，足够用来判断键唯一的列数。
>
> InnoDB Instrinsic Tables：InnoDB引擎内部的表，没有undo和redo，用户不可创建，只供引擎内部使用。
>
> ![img](/image/INDEX_Page_Overview.png)
>
> n_owned：在InnoDB中，表是按照B+Tree的方式存储。每个页中，都有一个PageDirectory(如上)。其中保存了该页内的record的偏移量。由于不是每个record在PageDirectory中都有一个slot（这称为sparse slots），因此每个record中就有了一个n_owned变量，保存了该recored所own的record数。
>
> ![image-20190530163445011](/image/innodb-page-directory.png)
>
> (Since the Page Directory does not have a slot for every record, binary search can only give a rough position and then `InnoDB` must follow the "next" record pointers. `InnoDB`'s "sparse slots" policy also accounts for the n_owned field in the Extra Bytes part of a record: n_owned indicates how many more records must be gone through because they don't have their own slots.

## Rowformat

- `REDUNDANT`：对于VARBINARY,VARCHAR,BLOB和 TEXT类型等类型，当长度超过767byte时，超过的部分会存储在额外的溢出页中。这是5.0.3之前的Row存储类型。之后的默认存储类型就是COMPACT。
- `COMPACT`：和REDUNANT类似，试试溢出也的存储更加紧凑，节省20%的空间。
- `DYNAMIC`：和上两个不同，当列值超过40byte时，那么行中只存储一个指针，指向附加页；然后每个附加页内还有一个指针指向后续数据，指针大小20byte。
- `COMPRESSED`：存储方式和DYNAMIC相似，只是该方式支持压缩表。

> | Row Format                              | `REDUNDANT`                      | `COMPACT`                        | `DYNAMIC`                | `COMPRESSED`             |
> | --------------------------------------- | -------------------------------- | -------------------------------- | ------------------------ | ------------------------ |
> | Compact Storage Characteristics         | No                               | Yes                              | Yes                      | Yes                      |
> | Enhanced Variable-Length Column Storage | No                               | No                               | Yes                      | Yes                      |
> | Large Index Key Prefix Support          | No                               | No                               | Yes                      | Yes                      |
> | Compression Support                     | No                               | No                               | No                       | Yes                      |
> | Supported Tablespace Types              | system, file-per table, general* | system, file-per-table, general* | file-per-table, general* | file-per-table, general* |
> | Required File Format                    | Antelope or Barracuda            | Antelope or Barracuda            | Barracuda                | Barracuda                |

## Redo LOG

在InnoDB中，其redo日志就是一种Physiological的日志。其中记录了数据页上的所有变更操作。每个记录的形式如下：

![image-20190529113341412](/image/innodb-redo-rec.png)

redo日志的每个日志记录是按照磁盘扇区大小的**512byte**存储，而不是page大小（在percona的xtradb中，可以更改事务记录大小，从而更好的利用SSD等新存储介质），位于`$innodb_log_group_home_dir/ib_logfile`中，可能有多个文件。

```sql
mysql> show global variables like '%innodb_log_file%';
+---------------------------+----------+
| Variable_name             | Value    |
+---------------------------+----------+
| innodb_log_file_size      | 50331648 |
| innodb_log_files_in_group | 2        |
+---------------------------+----------+
2 rows in set (0.01 sec)
```

### 简述

和PostgreSQL的max_wal_size类似，ib_logfile的大小有上限（`innodb_log_file_size * innodb_log_files_in_group < 512GB`），如果设置的过小，为了确保重用redo日志时，被重用的redo日志对应的页已经刷盘；那么可能会频繁的刷脏，这是可以调大redo的整体大小。为了避免checkpoint的刷脏，将pagecleaner和用户线程会按照一些阈值点，进行提前刷脏。因此，业务**update的吞吐量**和**CHECKPOINT回收redo文件**都和这个相关。

因为，我们recovery的时候需要重做这些记录，但是我们并不知道crash的时候相应记录的修改有没有落盘，因此可能会多次执行，所以其中记录保证幂等性([idempotent](http://books.google.com/books?id=S_yHERPRZScC&lpg=PA543&ots=JJtxVQOEAi&dq=idempotent gray&pg=PA543#v=onepage&q=idempotent gray&f=false))。

其实当recovery的时候，和PostgreSQL类似会比较日志的lsn与页面的lsn的大小，只会重做lsn大的日志。

There used to be in the past (maybe there is still, in some incarnation) a non-free tool called Innodb hot backup, ibbackup. It used specially compiled innodb, with this flag on. The flag is not set otherwise

> **双一保证**
>
> 默认将`innodb_flush_log_at_trx_commit`设置为1，保证日志Write Ahead；除非系统层面保证了数据不会丢失，如**battery backed raid card**。
>
> 另外还有上层MySQL的`sync_binlog`；也需要设置为1，保证binlog落盘。

为了提高整体的吞吐量，InnoDB采用组提交的方式，从而减少刷盘的次数（LogBuffer）。

> 这里理解就是服务的吞吐量而不是响应时间，因为如果组没有满，就不刷盘的话，是不是就影响了前面事务的响应时间。在PostgreSQL中通过`commit_siblings`配置一个组提交启用的下限，避免系统负载比较低的时候的刷盘等待。

### log_t

> UNIV_HOTBACKUP
> 在InnoDB中，常见一个UNIV_HOTBACKUP宏；这是之前有一个收费的热备工具——ibbackup相关的。现在基本不用了。
> https://stackoverflow.com/questions/28916804/what-does-univ-hotbackup-mean-in-innodb-source

`log_t*	log_sys`是redo日志系统的关键全局变量。这里基于5.7版代码，逐一了解每个成员变量的含义。这里互斥锁的类型都是：ib_mutex_t；实际上是基于Futex机制实现的FutexMutex（Linux Fast userspace mutex）。

#### logbuffer接收redo copy

log_t主要负责三项事情：redo日志写入(拷贝)到缓冲区中；redo缓冲区刷盘；执行CHECKPOINT。因此，其中有两类偏移量：给redo可拷贝写入的buffer的位置（buf_free）、redo缓冲区向磁盘刷盘的位置（buf_next_to_write）。

- `log_flush_order_mutex`：InnoDB中多个bufferPool共享的flush_list上的锁；确保flush_list的顺序访问。

- `byte* buf_ptr`：未对齐的logbuf地址，大小应该是buf_size的两倍；

- `buf_size`：innodb_log_buffer_size配置的buffer大小，但可能会自动扩展。

- `unsigned long buf_free`：buf中空闲的第一个位置

- `max_buf_free`：推荐的buf_free的最大值；

  ```c
  void log_buffer_extend(len) {
  ...
  log_sys->max_buf_free = log_sys->buf_size / LOG_BUF_FLUSH_RATIO - LOG_BUF_FLUSH_MARGIN;
  ...
  }
  ```

  当buf_free超过该值时，可能触发用户线程去写redo；在事务拷redo 到buffer后，也会判断该值，如果超过buf_free，需要刷logbuffer，设置log_sys->`check_flush_or_checkpoint`为true。

- `check_flush_or_checkpoint`：该项为True，表示需要刷logbuffer、或者preflush pool page，或者做CHECKPOINT；

#### logbuffer进行刷盘

- `unsigned long buf_next_to_write`：准备flush的redolog的位置，执行完继续推进。
- `volatile bool	is_extending;`：为了避免redo日志过大超过buffer，当redo日志超过buf_size/2时，就会扩展；扩展后，就不会缩减。
- `write_lsn`/`current_flush_lsn`/`flushed_to_disk_lsn`：buf的刷盘分为两步write和sync，write_lsn是最近write的lsn；current_flush_lsn是正在执行write+flush操作的lsn；flushed_to_disk_lsn是已经flush到磁盘的lsn(注意这里是lsn，上面buf中的偏移是ulint)。
- `n_pending_flushes`/`flush_event`：当前等待redo sync的任务，最大值为1；有`mutex`控制对flush_event的互斥访问，从而设置n_pending_flushes。

#### checkpoint相关

- `log_group_capacity`：表示当前日志文件的总容量，值为:(Redo log文件总大小 - redo 文件个数 * LOG_FILE_HDR_SIZE) * 0.9，LOG_FILE_HDR_SIZE 为 4*512 字节；超过该容量会重用之前的日志，如果日志对应的page没有刷盘，那么就会丢失数据。

- `max_modified_age_async/max_modified_age_sync/max_checkpoint_age_async/max_checkpoint_age`：进行preflush和CHECKPOINT的一些阈值点。

  ![image-20190529170008180](/image/innodb-page-flush.png)

- `next_checkpoint_no`：每次CHECKPOINT后递增

- `last_checkpoint_lsn/next_checkpoint_lsn`：最近的CHECKPOINT点与当前的CHECKPOINT点；完成之后，last<-next；

- `append_on_checkpoint` ：5.7新增，checkpoint时需要额外记录的redo记录，需要在`mutex`下互斥访问。在做DDL时（例如增删列），会先将包含MLOG_FILE_RENAME2日志记录的buf挂到这个变量上。 在DDL完成后，再清理掉。(log_append_on_checkpoint),主要是防止DDL期间crash产生的数据词典不一致。

  ```c
  /** Set extra data to be written to the redo log during checkpoint.
  @param[in]	buf	data to be appended on checkpoint, or NULL
  @return pointer to previous data to be appended on checkpoint */
  mtr_buf_t*
  log_append_on_checkpoint(
  	mtr_buf_t*	buf)
  {
  	log_mutex_enter();
  	mtr_buf_t*	old = log_sys->append_on_checkpoint;
  	log_sys->append_on_checkpoint = buf;
  	log_mutex_exit();
  	return(old);
  }
  ```

- `n_pending_checkpoint_writes`：大于0时，表示有CHECKPOINT正在进行。如果此时用户发起CHECKPOINT，那么该值+1；结束后该值-1(`log_io_complete`)；

- `checkpoint_buf_ptr/checkpoint_buf`：像日志中写入CHECKPOINT信息的缓冲区

- `checkpoint_lock`：CHECKPOINT信息的缓冲区写入的互斥lock

将log_t上的操作如下图

![image-20190529175154766](/image/innodb-log-t.png)

用户线程执行的mtr结束后，需要将本地的日志copy到logbuffer中，同时将修改的脏页放到flush_list中。

### 插入一个元组的总体逻辑

![image-20190531182646289](/image/InnoDB-Insert.png)



### Btree的插入逻辑

![image-20190531182929715](/image/innodb-btree-insert.png)



### 插入一个元组的数据页redo日志的写逻辑

![image-20190531183018967](/image/page-redo-record.png)



## Undo LOG

相对于PostgreSQL中，将旧版本的数据放在当前文件中的方式；在InnoDB中，Undo日志记录了行的旧值，当需要找到旧版本的数据时，需要按照undo链进行寻找。有数据变更的事务都需要一个undo record，如下是一个**undo record**：

![image-20190528183043050](/image/image-20190528183043050.png)

- Primary_Key_Value：包括页号和物理位置。
- Old_trx_id：更新该行的事务号
- Old_values_on_that_row：更新前的数据值。

**undo log**就是某一个读写事务的**undo record**的集合。**undo log**存放在**undo log segment**中，**undo log segment**存放在**rollback segment**中。一个**undo log segment**可以存放多个**undo log**，但是同一时刻只能分配给一个事务使用。

不同数据库对象的**rollback segment**放在不同的表空间中，临时表的放在**globaltemp-tp**中，这些对象不需要恢复，因此这里的undo log不写redo；其他对象放在**undo-tb**中。

> 由`innodb_rollback_segments`定了了rollback segment的个数([1,128]），默认128个。每个rseg中，有1024个slot(用了存放undo log)；
>
> 128个rseg只有后96个是给用户表使用的，并且每个undo log只能同时给一个事务使用，因此整体的事务并发上限为96*1024。
>
> ![image-20190529095215812](/image/undo-innodb.png)

在MySQL中，事务默认是只读事务；如果后期发现有临时表的写入，就分配**临时表的rseg**；若判断为读写事务，则开始分配事务ID和**普通rseg**。

对于Insert插入的新数据，没有任何老事务可能会读取该新行，所以一般在事务结束后，就将undo log删除，这部分是`insert_undo`。而对于Update和delete的旧数据，需要进行保留，在InnoDB中将其归为一类：`update_undo`。

回滚段是资源是有限的，系统有purge线程定期回收回滚段；每个回滚段上有一个引用计数(`trx_ref_count`)，如果计数为0，表示没有事务在使用，那么purge线程就对其进行回收；回收时，会将该rseg标记为``skip_allocation`，表示该段暂缓分配。

## Crash Recovery

一般恢复分为三步，首先扫描数据；然后基于Redo进行重做；最后基于Undo进行回滚。

在InnoDB中，分为4步：

1. dwbuffer：首先恢复 Doublewrite Buffer中的数据

2. Scan：从磁盘中读取redo日志记录，插入按照LSN排序的红黑树中。

3. Redo：`recv_recovery_from_checkpoint_start`，将重做redo记录，并脏页插入到flush_list中；另外，undo记录也是受redo保护的(临时表除外临时表不记redo），也可以从redo中恢复。

4. Undo：`dict_boot`初始化数据字典子系统；`trx_sys_init_at_db_start`初始化事务子系统，undo段的初始化在此完成；

   ![image-20190529105306507](/image/init-undo.png)

   将Active的事务，进行回滚；对于Prepare的事务，如果对应的binlog已经提交，那么提交，否则回滚。

# MySQL的BinLog

在MySQL中，除了存储引擎InnoDB的日志外，自身还有一个BinLog，其中记录了对数据进行了修改（以及可能对数据有修改）的事件，主要用在主从复制和PITR场景中。

> BinLog除了记录修改数据的操作，还会记录元信息：
>
> + 确保操作重放的正确的额外信息
> + 错误码
> + binlog自身的维护信息，比如rotate事件。
>
> 除了Redo、undo、binlog这些用于恢复的日志，MySQL中还有一些用于记录的日志：Errorlog、General Query Log、Slow Query Log、DDL Log。

每个binlog的大小由`max_binlog_size`决定，当超过该参数大小，会切换到一个新的文件；注意，同一个事务的binlog应该放在一个binlog文件中，当存在一个很大的事务，可能会超过`max_binlog_size`。

在启动的时候，由binlog-format指定三种类型：statement、row、mixed。

+ statement：记录主上执行的语句

+ row：以主键为标识，记录相应行的变更。

+ mixed：默认使用statement，当MySQL认为[某个语句不能完全复制](https://dev.mysql.com/doc/refman/5.7/en/binary-log-mixed.html)，升级为记录row。

  

# Group Commit

在PostgreSQL中有一个参数[commit_delay](https://www.postgresql.org/docs/current/runtime-config-wal.html#GUC-COMMIT-DELAY)代表PostgreSQL中的组提交，即，相比于每个事务都刷盘，打开这个参数，PostgreSQL会等待一组事务然后一起提交；但并发高的时候能提高整体的吞吐量，但是在并发较低的时候。

当然，前提是PostgreSQL打开了`fsync`参数；另外考虑到并发低的时候，没有必要等待；这里当db的活动事务大于`commit_siblings`时，才会delay commit(group commit)。

同样地，在MySQL中为了解决fsync带来的tps吞吐瓶颈问题，也有Group Commit特性，但是MySQL中由于存储的redolog和上层的binlog需要保证XA一致性，因此实现起来相对复杂。

## binlog与redolog的一致性

InnoDB是MySQL默认支持的事务型存储引擎，当上层同时启用binlog时，为了保证上下日志的一致，需要采用XA 2pc进行两阶段提交。

1. Prepare InnoDB
   1. 在InnoDB的logbuffer中，写入prepare记录；
   2. **fsync**：日志文件刷盘；
   3. 获取`prepare_commit_mutex`。
2. Prepare binlog
   1. 将事务写入binlog；
   
   2. **fsync**：基于`sync_binlog`配置的行为，进行binlog刷盘。
   
      > **XA recovery**
      >
      > 如果这里binlog刷盘了，那么恢复的时候，该事务认为是提交的；如果在这之前crash了，该事务会被回滚。
3. Commit InnoDB
   1. 在logbuffer中，写入commit记录；
   2. 释放`prepare_commit_mutex`;
   3. **fsync**：日志文件刷盘
   4. 释放InnoDB的锁
4. Commit binlog
  
   1. 没什么特别需要做的

在多个事务并发的进行2PC提交的时候，redolog的写入顺序和binlog的写入顺序可能不一致；基于`prepare_commit_mutex`，确保三次刷盘操作的顺序，从而保证binlog与InnoDB的redolog的顺序是一致的。

> MySQL的主从复制一般基于binlog实现；

然而，由于存在这样一个互斥同步，导致第2步的binlog**不能进行组提交**；并且理想情况下，一个事务，只有一个fsync操作即可，然而这里进行三次，**性能上也不太乐观**；没有对此进行优化的之前，binlog除了作为存储模块还是事务调度模块，**模块不清晰**，不易于维护。

## binlog的group commit

上述基于`prepare_commit_mutex`的commit机制的临界区过大，使得整个并发度降低，从而整体的吞吐降低。

因此，将binlog的提交划分为三个阶段，每个阶段都有一个执行队列：

+ flush：write
+ sync：刷盘
+ commit：成功

进入某阶段的第一个thread作为leader，后续进来的都是follower；leader将该阶段的threads注册到下一阶段中，然后统一负责处理该阶段的任务（如果下一阶段不为空，那么该leader成为下一阶段的follower，因此最慢的sync阶段会累积很多任务），此时follower就是等待处理完成的通知；

```bash
8.0

cmake . -DFORCE_INSOURCE_BUILD=1

make

/Users/liuyangming/src/mysql-8.0.16/runtime_output_directory
```



# 参考文章

[Undo漫游]([http://mysql.taobao.org/monthly/2015/04/01/](http://mysql.taobao.org/monthly/2015/04/01/))

[binlog文档](https://dev.mysql.com/doc/internals/en/binary-log-overview.html)

[worklog-mysql-5223](https://dev.mysql.com/worklog/task/?id=5223)

[binlog-group-commit]([http://mysqlmusings.blogspot.com/2012/06/binary-log-group-commit-in-mysql-56.html](http://mysqlmusings.blogspot.com/2012/06/binary-log-group-commit-in-mysql-56.html))











