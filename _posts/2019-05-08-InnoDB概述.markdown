---
layout: post
title: 事务型存储引擎InnoDB概述
date: 2019-05-08 17:06
header-img: "img/head.jpg"
categories: jekyll update
tags:
  - InnoDB
typora-root-url: ../../yummyliu.github.io
---

* TOC
{:toc}
# InnoDB简述

![adb](/image/arch-db.png)

在一个数据库系统中，分为以上几个部分；因为MySQL是一个存储引擎可拔插的系统；InnoDB是其默认的事务性存储，即上图的Transaction Storage Manager部分。本文先简单介绍一下MySQL，然后从四个方面阐述InnoDB，希望希望了解InnoDB的人能有所收获：

![image-20190717105416865](/image/InnoDB概述.png)

类似PgSQL的多进程结构，MySQL是多线程结构，其中有如下的线程角色

- User thread：每个链接一个线程；
- Master thread：整体活动的调度；比如flush，purge，checkpoint，insert buffer merge等。
- IO threads
  - read threads：多线程的预读
  - write threads：多线程的后台写
  - Insert Buffer thread：Insert Buffer合并
  - log thread：刷新log
- Purge threads：周期性执行的垃圾回收
  - 清理index中的废弃值
  - 清理表中被标记为`deleted`的记录。
  - 清理undo日志中的历史记录（rollback segment）。
  
- 死锁检测/Page cleaner (flush)/FTS, Statistics, Monitor, Drop table, Dump

  buffer pool等任务线程

InnoDB承担了MySQL作为一个RDBMS的存储部分的工作，比如Lock管理，访问方法，日志管理以及缓冲区管理。

# InnoDB的访问方法

目前有三种Btree，Rtree（spatial index）,倒排索引（Full-Text Search Index）。这里以最常用的Btree为例进行介绍。

# 文件组织方式

在InnoDB中，frame代表内存的虚拟地址空间的一个16k单元，主要用在缓冲区管理中；page代表物理内存的一个16k单元，其中是需要写回到磁盘的数据；而Block代表一个Control Block（`buf_block_t`），对于每个frame对应一个ControlBlock结构进行控制信息管理，但这些信息不写回内存。

![innodb files](/image/innodb-tablespace.png)

在外存中，按照表空间（space）进行组织；当启动了`innodb_file_per_table`参数后，每个数据表对应一个文件（参看系统表：INFORMATION_SCHEMA.INNODB_SYS_DATAFILES）。但是全局共享的对象，需要放在共享的表空间space0（全局变量`：innodb_data_file_path，默认为ibdata1）中：

- data dictionary（InnoDB表的元信息）
- change buffer
- double write buffer
- undo log

每个space有若干个file或者diskpartition；其中spaceid=0为系统表空间，其中有一些全局共享的结构：

- 公共结构体：ibuf、trx、dict等
- doublewrite buffer
- 数据目录

每个file分为若干个segment；其中有LeafNodeSegment、NonLeafNodeSegment、rollbacksegment，见[General Tablespace](https://dev.mysql.com/doc/refman/5.7/en/general-tablespaces.html)。

每个segment中有若干个固定大小的page

- 对于uncompressed的表空间，page是16Kb；
- 对于compressed的表空间，page是1~16Kb。

> IBUF_TREE
>
> Insert Buffer是二级索引变更的缓存；之前只有insert操作，后来也支持了delete/update/purge操作，成为ChangeBuffer；但是命名上没有改变，在内存中还是叫InsertBuffer；在外存中，放在ibuf文件中。

————————————————————————————————————

版本<5.5，创建一个索引相当于重建一个表（**CopyTable**）。

版本>=5.5，加入了FastIndexCreate特性，但只对二级索引有效（**Inplace**）；索引中只有发起createindex时刻的数据，create index时只能读不能写。过程有主要有如下三步：

1. 扫描表，建立内存buffer和临时文件
2. 进行合并排序
3. 将行插入到索引中

版本>=5.6.7，加入了Online Create Index的特性，创建二级索引的时候可读可写（还是会短暂block一下，但是已经影响很小了）；对于创建索引过程中对表进行的修改，放在RowLog（不是redolog）中；

### Rowformat

- `REDUNDANT`：对于VARBINARY,VARCHAR,BLOB和 TEXT类型等类型，当长度超过767byte时，超过的部分会存储在额外的溢出页中。这是5.0.3之前的Row存储类型。之后的默认存储类型就是COMPACT。
- `COMPACT`：和REDUNANT类似，试试溢出也的存储更加紧凑，节省20%的空间。
- `DYNAMIC`：和上两个不同，当列值超过40byte时，那么行中只存储一个指针，指向附加页；然后每个附加页内还有一个指针指向后续数据，指针大小20byte。
- `COMPRESSED`：存储方式和DYNAMIC相似，只是该方式支持压缩表。

> | Row Format                              | `REDUNDANT`                      | `COMPACT`                        | `DYNAMIC`                | `COMPRESSED`             |
> | --------------------------------------- | -------------------------------- | -------------------------------- | ------------------------ | ------------------------ |
> | Compact Storage Characteristics         | No                               | Yes                              | Yes                      | Yes                      |
> | Enhanced Variable-Length Column Storage | No                               | No                               | Yes                      | Yes                      |
> | Large Index Key Prefix Support          | No                               | No                               | Yes                      | Yes                      |
> | Compression Support                     | No                               | No                               | No                       | Yes                      |
> | Supported Tablespace Types              | system, file-per table, general* | system, file-per-table, general* | file-per-table, general* | file-per-table, general* |
> | Required File Format                    | Antelope or Barracuda            | Antelope or Barracuda            | Barracuda                | Barracuda                |



## Btree的创建

## Btree的插入

在插入的时候，按照如下情况，当前page放不下了。

![Page Merging and Page Splitting](/image/Locality_7.png)

那么，按照next指针找到下一个page，下一个page已经满了。

![Page Merging and Page Splitting](/image/Locality_9.png)

这是就需要进行节点分裂，大概有4步:

1. 创建一个新的page
2. 确定要分裂的page以及要分裂的位置。
3. 移动记录
4. 修改next和prev指针等节点信息。

```sql
SET GLOBAL innodb_monitor_enable = index_page_splits;
SET GLOBAL innodb_monitor_enable = index_page_reorg_attempts;
select * from INFORMATION_SCHEMA.INNODB_METRICS where name = 'index_page_reorg_attempts'\G
select * from INFORMATION_SCHEMA.INNODB_METRICS where name = 'index_page_splits'\G
```



## Btree的删除

BtreePage中有一个MERGE_THRESHOLD，默认是0.5；当BtreePage由于delete或者update（新记录的大小比历史记录小）使得容量小于0.5；那么就会通过前向和后向指针查看相邻节点时候也可以merge。

如下，当删除了记录，直到page中的记录大小小于阈值。

![img](/image/Locality_3.png)

![img](/image/Locality_4.png)

那么就会和相邻节点进行合并；将后续节点的数据复制到前面的节点中，那么另一个节点就成空节点了，可以用来放新的数据。

![img](/image/Locality_5.png)

![Page Merging and Page Splitting](/image/Locality_6.png)

监控

```sql
SET GLOBAL innodb_monitor_enable = index_page_merge_successful;
select * from INFORMATION_SCHEMA.INNODB_METRICS where name = 'index_page_merge_successful'\G
```



# InnoDB缓冲区管理

在InnoDB中，有如下一些缓冲区；大类上和PgSQL相似都有一个放数据页的BufferPool，和一个放日志记录的LogBuffer。在CHECKPOINT的调度下，进行BufferPool刷盘；每次事务commit进行LogBuffer刷盘。

除了这两个之外，还有为了减小二级索引的写放大，引入的Change Buffer机制；为了避免数据部分写，引入的DoubleWrite Buffer。

> 另外，还有存储元数据目录与其他内部结果的Memory Pool，由参数`innodb_additional_mem_pool_size`控制，默认8MB；这个如果不够就会动态申请，然后再日志中写warning记录。


## Change Buffer

当二级索引的块不在缓存中时，允许将相应更改缓存起来。包括三类更改：insert/delete/purge。

当changeBuffer满了，会读取相应的页，按照changeBuffer进行merge。

1. 随机选择changeBuffer中一个随机页。
2. 随机打开该页中的一个cursor。
3. 按照该cursor，读取之后的至多8个页。
4. 异步发起IO请求；当读取完成后，调用回调函数，执行相应的change。

## Buffer Pool

存放表和索引的数据，由`innodb_buffer_pool_size`设置，默认是128MB；推荐配置为系统物理内存的80%。

### CHECKPOINT

CHECKPOINT在DBMS都是同一个概念，其为redo日志中的一条记录，其表示在该记录之前的数据页的更改已经从缓冲区写入磁盘了。

> 有两种类型的CHECKPOINT：
>
> **sharp checkpoint**:
>
> 只将commited的事务修改的页进行刷盘，并且记下最新Commited的事务的LSN。这样恢复的时候，redo日志从CHECKPOINT发生的LSN开始恢复即可。由于所有刷盘的数据都是在同一个点(CHECKPOINT LSN)之后，所以称之为sharp。
>
> **fuzzy checkpoint:**
>
> 如果脏页滞留到一定时间，就可能会刷盘。这种方式在日志中写下两个LSN：CHECKPOINT start和CHECKPOINT end。当恢复的时候，还是从CHECKPOINT start开始恢复。
>
> ——[Gray and Reuter’s classic text on transaction processing](https://www.amazon.com/gp/product/1558601902/?tag=xaprb-20)

在InnoDB中，除了shutdown的时候，正常时候都是fuzzy CHECKPOINT。刷盘前，能够多次修改，这样省去了很多IO。

池中的页由三个list维护，分别是：

+ free_list：可用的页
+ LRU_list：最近使用的页
+ flush_list：按照LSN的顺序组织的脏页（即，最近修改的页）。

由于buffer池是有限的，不能只是等满了才进行页换出（LRU_list）；所以，InnoDB会持续地进行CHECKPOINT，这里主要和flush_list相关。基于flush_list的换出就是选择最早更改的脏页(LSN)进行换出。因此，InnoDB中的换出有两种情况。

- BufferPool满了之后，基于LRU_list，进行页面置换。
- 主动进行刷盘，基于flush_list，其中按照修改的先后顺序排列。

> 为了避免将热数据换出，所以选择了最早更改的脏页。另外，由于事务日志（即，redo/wal日志）是固定大小的，因此，redo日志是循环使用的。当最早的日志记录相应的页一直没有刷盘，如果此时发生了日志重用，那么更改就没有持久化(违反D)；因此，当这种情况发生时，InnoDB需要夯住，进行刷盘（同样这也是为什么选择最早更改的脏页的一个原因）。
>

综上，当InnoDB执行fuzzy CHECKPOINT的时候，其会找到flush_list中的最早更改的脏页的LSN，将其作为CHECKPOINT的start，写入事务日志头中(参见源码：`log_checkpoint_margin`和`log_checkpoint`)。

而当InnoDB停机时，做法就是sharp checkpoint。首先，停止数据更新；然后，将脏页刷盘；最后，将当前的LSN写入事务日志头中。

> 另外，在Percona版本的XtraDB中，提供了一种基于代价的 adaptive CHECKPOINT；以及InnoDB后来也有了[adaptive flushing]([http://dimitrik.free.fr/blog/archives/2010/07/mysql-performance-innodb-io-capacity-flushing.html](http://dimitrik.free.fr/blog/archives/2010/07/mysql-performance-innodb-io-capacity-flushing.html))。

## Doublewrite Buffer(disk)

InnoDB的页大小是16k，但是OS每次是按照4K写入，因此可能存在16K部分写的情况下，系统crash了。为了避免这一问题，设计了doublewrite_buffer。

dwbuffer可以看做是存在于**系统表空间**中的一个短期的日志文件，它包含了100个页。当InnoDB刷页时，会先将页**顺序**写入到dwbuffer中，并将dwbuffer刷盘；然后，将页刷到真正的数据文件中。

当recovery时，InnoDB检查dwbuffer中页和其本来位置的页的内容；如果dwbuffer中的页是不一致的，那么丢弃该页；如果表中的页是不一致的，那么从dwbuffer中恢复。

性能上，尽管每次写页的时候需要写两次；但是由于将dwbuffer的写是顺序的，并且不会每个page调用一次fsync，而是一起fsync；整体性能比原来损失经验值是5%。

> 如果你不在乎数据丢失，或者OS级别保证了不会有部分写，那么可以`innodb_doublewrite=0` 关闭double write。

## Log Buffer

InnoDB的表发生变更的时候，首先将变更存储在Log Buffer中，然后写入到Redo日志中。其由`innodb_log_buffer_size`设置，默认16MB；当大事务中的insert/update/delete比较多时，将提高该参数可以减少磁盘IO；通过观察系统参数`innodb_log_waits`，可以得知是否需要调大LogBuffer。

```sql
SELECT name, subsystem, status FROM INFORMATION_SCHEMA.INNODB_METRICS;
```

# InnoDB日志管理

数据库日志是保证事务的ACID的重要机制，按照数据恢复的一般算法**ARIES**如下，数据库的日志一般有两种：REDO和UNDO；另外，在MySQL层，还有一个BinLog，但其不属于InnoDB。

> ARIES
>
> - Write ahead logging
> - Rpeating history during Redo
> - Logging change during Undo

日志一般分为三种：

- 纯物理日志：记录数据页的物理字节位置和内容。
- 纯逻辑日志：记录更改的语句。
- 物理的逻辑日志（Physiological Log）：记录物理页中更改的逻辑，这里的逻辑不是SQL逻辑，而是物理页中的变更操作。

现代DBMS中，一般采用的是Physiological方式。其日志体积更小，恢复更快，并且解决了逻辑日志的非幂等性。

> **逻辑日志的非幂等性**
>
> 比如，逻辑日志中有一个insert a in A，其需要更新数据和索引页。但是crash的时候，可能只更新了data，没有更新index。

## MTR

以向一级索引中，插入一条元组为例；如果有相同健值的元组，那么存在两种情况：

1. 该元组已经被一个commited的事务标记删除了
2. 返回主键冲突的异常

对于第一种情况，当前的insert事务需要针对标记删除的元组写一个undolog。

> dict_index_t->n_uniq：在dict_index_t->n_fields中，从前向后，足够用来判断键唯一的列数。
>
> InnoDB Instrinsic Tables：InnoDB引擎内部的表，没有undo和redo，用户不可创建，只供引擎内部使用。
>
> ![img](/image/INDEX_Page_Overview.png)
>
> n_owned：在InnoDB中，表是按照B+Tree的方式存储。每个页中，都有一个PageDirectory(如上)。其中保存了该页内的record的偏移量。由于不是每个record在PageDirectory中都有一个slot（这称为sparse slots），因此每个record中就有了一个n_owned变量，保存了该recored所own的record数。
>
> ![image-20190530163445011](/image/innodb-page-directory.png)
>
> (Since the Page Directory does not have a slot for every record, binary search can only give a rough position and then `InnoDB` must follow the "next" record pointers. `InnoDB`'s "sparse slots" policy also accounts for the n_owned field in the Extra Bytes part of a record: n_owned indicates how many more records must be gone through because they don't have their own slots.

## Redo LOG

在InnoDB中，其redo日志就是一种Physiological的日志。其中记录了数据页上的所有变更操作。每个记录的形式如下：

![image-20190529113341412](/image/innodb-redo-rec.png)

redo日志的每个日志记录是按照磁盘扇区大小的**512byte**存储，而不是page大小（在percona的xtradb中，可以更改事务记录大小，从而更好的利用SSD等新存储介质），位于`$innodb_log_group_home_dir/ib_logfile`中，可能有多个文件。

```sql
mysql> show global variables like '%innodb_log_file%';
+---------------------------+----------+
| Variable_name             | Value    |
+---------------------------+----------+
| innodb_log_file_size      | 50331648 |
| innodb_log_files_in_group | 2        |
+---------------------------+----------+
2 rows in set (0.01 sec)
```

### 简述

和PostgreSQL的max_wal_size类似，ib_logfile的大小有上限（`innodb_log_file_size * innodb_log_files_in_group < 512GB`），如果设置的过小，为了确保重用redo日志时，被重用的redo日志对应的页已经刷盘；那么可能会频繁的刷脏，这是可以调大redo的整体大小。为了避免checkpoint的刷脏，将pagecleaner和用户线程会按照一些阈值点，进行提前刷脏。因此，业务**update的吞吐量**和**CHECKPOINT回收redo文件**都和这个相关。

因为，我们recovery的时候需要重做这些记录，但是我们并不知道crash的时候相应记录的修改有没有落盘，因此可能会多次执行，所以其中记录保证幂等性([idempotent](http://books.google.com/books?id=S_yHERPRZScC&lpg=PA543&ots=JJtxVQOEAi&dq=idempotent gray&pg=PA543#v=onepage&q=idempotent gray&f=false))。

其实当recovery的时候，和PostgreSQL类似会比较日志的lsn与页面的lsn的大小，只会重做lsn大的日志。

There used to be in the past (maybe there is still, in some incarnation) a non-free tool called Innodb hot backup, ibbackup. It used specially compiled innodb, with this flag on. The flag is not set otherwise

> **双一保证**
>
> 默认将`innodb_flush_log_at_trx_commit`设置为1，保证日志Write Ahead；除非系统层面保证了数据不会丢失，如**battery backed raid card**。
>
> 另外还有上层MySQL的`sync_binlog`；也需要设置为1，保证binlog落盘。

为了提高整体的吞吐量，InnoDB采用组提交的方式，从而减少刷盘的次数（LogBuffer）。

> 这里理解就是服务的吞吐量而不是响应时间，因为如果组没有满，就不刷盘的话，是不是就影响了前面事务的响应时间。在PostgreSQL中通过`commit_siblings`配置一个组提交启用的下限，避免系统负载比较低的时候的刷盘等待。

### log_t

> UNIV_HOTBACKUP
> 在InnoDB中，常见一个UNIV_HOTBACKUP宏；这是之前有一个收费的热备工具——ibbackup相关的。现在基本不用了。
> https://stackoverflow.com/questions/28916804/what-does-univ-hotbackup-mean-in-innodb-source

`log_t*	log_sys`是redo日志系统的关键全局变量。这里基于5.7版代码，逐一了解每个成员变量的含义。这里互斥锁的类型都是：ib_mutex_t；实际上是基于Futex机制实现的FutexMutex（Linux Fast userspace mutex）。

#### logbuffer接收redo copy

log_t主要负责三项事情：redo日志写入(拷贝)到缓冲区中；redo缓冲区刷盘；执行CHECKPOINT。因此，其中有两类偏移量：给redo可拷贝写入的buffer的位置（buf_free）、redo缓冲区向磁盘刷盘的位置（buf_next_to_write）。

- `log_flush_order_mutex`：InnoDB中多个bufferPool共享的flush_list上的锁；确保flush_list的顺序访问。

- `byte* buf_ptr`：未对齐的logbuf地址，大小应该是buf_size的两倍；

- `buf_size`：innodb_log_buffer_size配置的buffer大小，但可能会自动扩展。

- `unsigned long buf_free`：buf中空闲的第一个位置

- `max_buf_free`：推荐的buf_free的最大值；

  ```c
  void log_buffer_extend(len) {
  ...
  log_sys->max_buf_free = log_sys->buf_size / LOG_BUF_FLUSH_RATIO - LOG_BUF_FLUSH_MARGIN;
  ...
  }
  ```

  当buf_free超过该值时，可能触发用户线程去写redo；在事务拷redo 到buffer后，也会判断该值，如果超过buf_free，需要刷logbuffer，设置log_sys->`check_flush_or_checkpoint`为true。

- `check_flush_or_checkpoint`：该项为True，表示需要刷logbuffer、或者preflush pool page，或者做CHECKPOINT；

#### logbuffer进行刷盘

- `unsigned long buf_next_to_write`：准备flush的redolog的位置，执行完继续推进。
- `volatile bool	is_extending;`：为了避免redo日志过大超过buffer，当redo日志超过buf_size/2时，就会扩展；扩展后，就不会缩减。
- `write_lsn`/`current_flush_lsn`/`flushed_to_disk_lsn`：buf的刷盘分为两步write和sync，write_lsn是最近write的lsn；current_flush_lsn是正在执行write+flush操作的lsn；flushed_to_disk_lsn是已经flush到磁盘的lsn(注意这里是lsn，上面buf中的偏移是ulint)。
- `n_pending_flushes`/`flush_event`：当前等待redo sync的任务，最大值为1；有`mutex`控制对flush_event的互斥访问，从而设置n_pending_flushes。

#### checkpoint相关

- `log_group_capacity`：表示当前日志文件的总容量，值为:(Redo log文件总大小 - redo 文件个数 * LOG_FILE_HDR_SIZE) * 0.9，LOG_FILE_HDR_SIZE 为 4*512 字节；超过该容量会重用之前的日志，如果日志对应的page没有刷盘，那么就会丢失数据。

- `max_modified_age_async/max_modified_age_sync/max_checkpoint_age_async/max_checkpoint_age`：进行preflush和CHECKPOINT的一些阈值点。

  ![image-20190529170008180](/image/innodb-page-flush.png)

- `next_checkpoint_no`：每次CHECKPOINT后递增

- `last_checkpoint_lsn/next_checkpoint_lsn`：最近的CHECKPOINT点与当前的CHECKPOINT点；完成之后，last<-next；

- `append_on_checkpoint` ：5.7新增，checkpoint时需要额外记录的redo记录，需要在`mutex`下互斥访问。在做DDL时（例如增删列），会先将包含MLOG_FILE_RENAME2日志记录的buf挂到这个变量上。 在DDL完成后，再清理掉。(log_append_on_checkpoint),主要是防止DDL期间crash产生的数据词典不一致。

  ```c
  /** Set extra data to be written to the redo log during checkpoint.
  @param[in]	buf	data to be appended on checkpoint, or NULL
  @return pointer to previous data to be appended on checkpoint */
  mtr_buf_t*
  log_append_on_checkpoint(
  	mtr_buf_t*	buf)
  {
  	log_mutex_enter();
  	mtr_buf_t*	old = log_sys->append_on_checkpoint;
  	log_sys->append_on_checkpoint = buf;
  	log_mutex_exit();
  	return(old);
  }
  ```

- `n_pending_checkpoint_writes`：大于0时，表示有CHECKPOINT正在进行。如果此时用户发起CHECKPOINT，那么该值+1；结束后该值-1(`log_io_complete`)；

- `checkpoint_buf_ptr/checkpoint_buf`：像日志中写入CHECKPOINT信息的缓冲区

- `checkpoint_lock`：CHECKPOINT信息的缓冲区写入的互斥lock

将log_t上的操作如下图

![image-20190529175154766](/image/innodb-log-t.png)

用户线程执行的mtr结束后，需要将本地的日志copy到logbuffer中，同时将修改的脏页放到flush_list中。

### 插入一个元组的总体逻辑

row_ins_clust_index_entry_low

![image-20190603094352875](/image/innodb-insert-overview.png)



### Btree的插入逻辑

![image-20190531182929715](/image/innodb-btree-insert.png)



### 插入一个元组的数据页redo日志的写逻辑

![image-20190531183018967](/image/page-redo-record.png)



## Undo LOG

相对于PostgreSQL中，将旧版本的数据放在当前文件中的方式；在InnoDB中，Undo日志记录了行的旧值，当需要找到旧版本的数据时，需要按照undo链进行寻找。有数据变更的事务都需要一个undo record，如下是一个**undo record**：

![image-20190528183043050](/image/image-20190528183043050.png)

- Primary_Key_Value：包括页号和物理位置。
- Old_trx_id：更新该行的事务号
- Old_values_on_that_row：更新前的数据值。

**undo log**就是某一个读写事务的**undo record**的集合。**undo log**存放在**undo log segment**中，**undo log segment**存放在**rollback segment**中。一个**undo log segment**可以存放多个**undo log**，但是同一时刻只能分配给一个事务使用。

不同数据库对象的**rollback segment**放在不同的表空间中，临时表的放在**globaltemp-tp**中，这些对象不需要恢复，因此这里的undo log不写redo；其他对象放在**undo-tb**中。

> 由`innodb_rollback_segments`定了了rollback segment的个数([1,128]），默认128个。每个rseg中，有1024个slot(用了存放undo log)；
>
> 128个rseg只有后96个是给用户表使用的，并且每个undo log只能同时给一个事务使用，因此整体的事务并发上限为96*1024。
>
> ![image-20190529095215812](/image/undo-innodb.png)

在MySQL中，事务默认是只读事务；如果后期发现有临时表的写入，就分配**临时表的rseg**；若判断为读写事务，则开始分配事务ID和**普通rseg**。

对于Insert插入的新数据，没有任何老事务可能会读取该新行，所以一般在事务结束后，就将undo log删除，这部分是`insert_undo`。而对于Update和delete的旧数据，需要进行保留，在InnoDB中将其归为一类：`update_undo`。

回滚段是资源是有限的，系统有purge线程定期回收回滚段；每个回滚段上有一个引用计数(`trx_ref_count`)，如果计数为0，表示没有事务在使用，那么purge线程就对其进行回收；回收时，会将该rseg标记为``skip_allocation`，表示该段暂缓分配。

## Crash Recovery

一般恢复分为三步，首先扫描数据；然后基于Redo进行重做；最后基于Undo进行回滚。

在InnoDB中，分为4步：

1. dwbuffer：首先恢复 Doublewrite Buffer中的数据

2. Scan：从磁盘中读取redo日志记录，插入按照LSN排序的红黑树中。

3. Redo：`recv_recovery_from_checkpoint_start`，将重做redo记录，并脏页插入到flush_list中；另外，undo记录也是受redo保护的(临时表除外临时表不记redo），也可以从redo中恢复。

4. Undo：`dict_boot`初始化数据字典子系统；`trx_sys_init_at_db_start`初始化事务子系统，undo段的初始化在此完成；

   ![image-20190529105306507](/image/init-undo.png)

   将Active的事务，进行回滚；对于Prepare的事务，如果对应的binlog已经提交，那么提交，否则回滚。



# InnoDB的锁管理器

## 显式事务锁

描述一个锁从两个维度：粒度和力度。在InnoDB中，从粒度上分为表锁和行锁；在不同的粒度上，又根据力度的不同分为不同类型。但都是在一个结构中表示`lock_t`，根据`is_record_lock`（提取type_mode的标记为）来判断锁的粒度。

```c
	/** Determine if the lock object is a record lock.
	@return true if record lock, false otherwise. */
	bool is_record_lock() const
	{
		return(type() == LOCK_REC);
	}
	ulint type() const {
		return(type_mode & LOCK_TYPE_MASK);
	}
```

type_mode是一个无符号的32位整型，低1字节为lock_mode；低2字节为lock_type；再高的字节为行锁的类型标记，如下定义：

```c
/** Lock modes and types */
/* Basic lock modes */
enum lock_mode {
	LOCK_IS = 0,	/* intention shared */
	LOCK_IX,	/* intention exclusive */
	LOCK_S,		/* shared */
	LOCK_X,		/* exclusive */
	LOCK_AUTO_INC,	/* locks the auto-inc counter of a table in an exclusive mode */
	LOCK_NONE,	/* this is used elsewhere to note consistent read */
	LOCK_NUM = LOCK_NONE, /* number of lock modes */
	LOCK_NONE_UNSET = 255
};
/* @{ */
#define LOCK_MODE_MASK	0xFUL	/*!< mask used to extract mode from the
				type_mode field in a lock */
/** Lock types */
/* @{ */
#define LOCK_TABLE	16	/*!< table lock */
#define	LOCK_REC	32	/*!< record lock */
#define LOCK_TYPE_MASK	0xF0UL	/*!< mask used to extract lock type from the
				type_mode field in a lock */
#define LOCK_ORDINARY	0	/*!< this flag denotes an ordinary
				next-key lock in contrast to LOCK_GAP
				or LOCK_REC_NOT_GAP */
#define LOCK_GAP	512	
#define LOCK_REC_NOT_GAP 1024	
#define LOCK_INSERT_INTENTION 2048 
#define LOCK_PREDICATE	8192	/*!< Predicate lock */
#define LOCK_PRDT_PAGE	16384	/*!< Page lock */
```

### 表锁

在MySQL中，有表锁和行锁；在DML中，一般就是行锁，默认的存储引擎InnoDB实现的就是行锁，有X/S两种模式（5.7中加了SX模式）。

当我们要对某个page中的一行记录进行锁定时，需要对上层的table加意向锁——IS/IX，意为该事务中有意向对表中的某些行加X、S锁。意向锁是InnoDB存储引擎自己维护的，用户无法手动添加意向锁。

通过阅读代码，可以看出执行每次操作MySQL上层直接发起`MySQL_lock_table->Innodb::external_lock(F_WRLCK/F_RDLCK)`。结束之后再`MySQL_unlock_table->Innodb::external_lock(F_UNLCK) `。其中模式只有三种（直接使用的Linux文件操作的宏定义）如下：

```c
#define F_RDLCK 0
#define F_WRLCK 1
#define F_UNLCK 2
// 这是linux头文件中的定义；但是在my_global.h中，是
#define F_RDLCK 1
#define F_WRLCK 2
#define F_UNLCK 3
// 注意区分
```

注意意向锁是表级别的锁（其实就是在整个一级索引上加index->lock），其和表锁X/S有相应的兼容性判断：

| -    | IS               | IX     | S      | X                |
| ---- | ---------------- | ------ | ------ | ---------------- |
| IS   | 兼容(compatible) | 兼容   | 兼容   | 不兼容(conflict) |
| IX   | 兼容             | 兼容   | 不兼容 | 不兼容           |
| S    | 兼容             | 不兼容 | 兼容   | 不兼容           |
| X    | 不兼容           | 不兼容 | 不兼容 | 不兼容           |

————————————————————————————————————

除了通过锁来进行并发控制（**一致性锁定读**，select for update/select for shared/update where / delete where）；另外，在默认情况下。事务第一次读的时候会通过undo空间提供的多版本，构建一个readview，提供**一致性非锁定读**；这就是RR级别下，可重复读的实现方式。比如，`mysqldump --single-transaction`时，就是基于RR级别的读快照进行导出。

————————————————————————————————————

另外，还有一种特殊的表锁：Auto-Inc Lock，当有AUTO_INCREMENT列时，插入数据时会有这个锁，由参数**innodb_autoinc_lock_mode**控制自增长的控制算法。由于并发插入的存在，自增长的值是不连续的；那么，基于statement的主从复制可能出现问题；因此，启用auto_increment后，需要是有row模式的主从复制。

### 行锁

![image-20190712104111800](/image/InnoDB-lock.png)

- **Record Lock**：基于主键锁定某个记录

- **Gap Lock**：要求隔离级别是RR，并且innodb_locks_unsafe_for_binlog=0；这时，如果查询走非唯一索引或者查询是范围读，那么会加GapLock。

- **Next-Key Lock**：前提是启用了GapLock，其是Record Lock和该Record之前区间的Gap Lock的结合；否则，只是recordLock。

  当给一个record加x/s锁时，其实是给该record加recordlock，和该record之前的一个gap加了gaplock；即给一个左开右闭的区间加了锁。避免幻读。

  当查询的索引具有唯一性时，Next-Key Lock降级为Record Lock。

- **Insert Intention Lock**：Insert语句的特殊的GapLock；gap锁存在的唯一目的是防止有其他事务进行插入，从而造成幻读。假如利用gap锁来代替插入意向锁，那么两个事务则不能同时对一个gap进行插入。因此为了更高的并发性所以使用插入意向gap锁；插入意向锁的使得insert同一个间隙的不同键值的查询之间不阻塞，提高并发；但是还是会阻塞update、delete操作。

  当多个事务在**同一区间**（gap）插入**位置不同**的多条数据时，事务之间**不需要互相等待**

> `innodb_locks_unsafe_for_binlog`
>
> 该参数的作用和将隔离级别设置为 READ COMMITTED相同，是一个将要废弃的参数。

> **监控视图**
>
> ```sql
> select * from information_schema.innodb_trx\G; -- 查看当前的事务信息
> select * from information_schema.innodb_locks\G; --查看当前的锁信息
> select * from information_schema.innodb_lock_waits\G; --- 查看当前的锁等待信息
> --可以联表查，查找自己想要的结果。
> select * from sys.innodb_lock_waits\G; -- 查看当前的锁等待信息
> show engine innodb status\G;
> ---还可以通过当前执行了执行了什么语句
> select * from  performance_schema.events_statements_current\G; 
> show full processlist;
> ```

> **注意** 在MySQL的默认隔离级别RR下，同样比标准SQL更加严格，即，没有幻读；但是[没有幻读有幻写](https://blog.pythian.com/understanding-mysql-isolation-levels-repeatable-read/)
>
> - 其他事务更新了数据
>
> ```sql
> mysql> start transaction;
> mysql> select * from t;
> +-----+--------+------+---------+------+
> | a   | b      | c    | d       | e    |
> +-----+--------+------+---------+------+
> ...
> | 394 | asdf | asdf | asdf    |  399 |
> | 395 | asdf | asdf | asdf    |  400 |
> | 397 | asdf | asdf | asdfasd |  402 |
> +-----+------+------+---------+------+
> Query OK, 0 rows affected (0.00 sec)
> mysql> select * from t where a = 396;
> Empty set (0.00 sec)
> 
> mysql> update t set b = 'pwrite' where a = 396;
> Query OK, 1 row affected (0.00 sec)
> Rows matched: 1  Changed: 1  Warnings: 0
> 
> mysql> select * from t where a = 396;
> +-----+--------+------+---------+------+
> | a   | b      | c    | d       | e    |
> +-----+--------+------+---------+------+
> | 396 | pwrite | asdf | asdfasd |  402 |
> +-----+--------+------+---------+------+
> 1 row in set (0.00 sec)
> 
> mysql> commit;
> Query OK, 0 rows affected (0.01 sec)
> ```
>
> 在第3行查询之前，在另一个事务中执行如下更新：
>
> ```sql
> update t set a = 396 where e = 402;
> ```
>
> - 其他事务插入了数据
>
> ```sql
> | 395 | asdf       | asdf | asdf    |  400 |
> | 396 | pwrite     | asdf | asdfasd |  402 |
> | 397 | new insert | asdf | s       |  403 |
> | 398 | new insert | s    | s       |  404 |
> +-----+------------+------+---------+------+
> 399 rows in set (0.01 sec)
> 
> mysql> update t set e=405 where a = 399;
> Query OK, 0 rows affected (0.00 sec)
> Rows matched: 1  Changed: 0  Warnings: 0
> 
> mysql> commit;
> Query OK, 0 rows affected (0.00 sec)
> ```
>
> 发现：
>
> 当前事务select不可见，即，不能看到新事务提交的数据，满足可重复读；
>
> 但是当前事务执行update，却能够更新；更新之后再select，可以看到这个新元组？
>
> 因此，可知MySQL的RR级别的实现，在read的时候确实更加严格没有幻读了。但是，事务需要修改的时候，对于其他事务新插入的数据，是不能看到的；对于其他事务修改的数据是可以看到了的，😹还有这种操作。。。
>
> 因此，对于MySQL的RR级别，有如下结论：
>
> 1. 当只是select语句时，是没有幻读（Phantom Read）的；比如*mysqldump with –single-transaction*。
> 2. 当事务修改数据了，RR级别的表现是有所不同；对于没有修改的行，是RR；对于修改的行，是RC。因为，SQL标准中对此没有定义，那么也不能说违反了SQL语义。
> 3. 当事务写了新数据时，该事务就使用已经提交的数据，而不是该事务的readview；所以，InnoDB的事务修改总是基于最新的提交的数据进行修改。

## 隐式内存锁

```c
/* The hash table structure */
struct hash_table_t {
	enum hash_table_sync_t	type;	/*<! type of hash_table. */
#if defined UNIV_AHI_DEBUG || defined UNIV_DEBUG
# ifndef UNIV_HOTBACKUP
	ibool			adaptive;/* TRUE if this is the hash
					table of the adaptive hash
					index */
# endif /* !UNIV_HOTBACKUP */
#endif /* UNIV_AHI_DEBUG || UNIV_DEBUG */
	ulint			n_cells;/* number of cells in the hash table */
	hash_cell_t*		array;	/*!< pointer to cell array */
#ifndef UNIV_HOTBACKUP
	ulint			n_sync_obj;/* if sync_objs != NULL, then
					the number of either the number
					of mutexes or the number of
					rw_locks depending on the type.
					Must be a power of 2 */
	union {
		ib_mutex_t*	mutexes;/* NULL, or an array of mutexes
					used to protect segments of the
					hash table */
		rw_lock_t*	rw_locks;/* NULL, or an array of rw_lcoks
					used to protect segments of the
					hash table */
	} sync_obj;

	mem_heap_t**		heaps;	/*!< if this is non-NULL, hash
					chain nodes for external chaining
					can be allocated from these memory
					heaps; there are then n_mutexes
					many of these heaps */
#endif /* !UNIV_HOTBACKUP */
	mem_heap_t*		heap;
#ifdef UNIV_DEBUG
	ulint			magic_n;
# define HASH_TABLE_MAGIC_N	76561114
#endif /* UNIV_DEBUG */
};
```

内存锁的对象是buf_page中的page，即`buf_pool->page_hash`；page_hash是如上结果的hash表；其中的sync_obj就是该hash表中的元素的锁，有两种：mutex和rw_lock。

### mutex

上述的事务锁是和Transaction相关的并发控制；而在InnoDB的内存中，还有基于系统提供的原子操作，和用户线程相关的存并发访问机制（latch），分为两种：

1. **mutex（sync0sync.h）**，内存结构的串行访问，主要用在一些共享的数据结构上。

- Dictionary mutex（Dictionary header)
- Transaction undo mutex，Transaction system header的并发访问，在修改indexpage前，在Transaction system的header中写入一个undo log entry。
- Rollback segment mutex，Rollback segment header的并发访问，当需要在回滚段中添加一个新的undopage时，需要申请这个mutex。
- lock_sys_wait_mutex：lock timeout data
- lock_sys_mutex：lock_sys_t
- trx_sys_mutex：trx_sys_t
- Thread mutex：后台线程调度的mutex
- query_thr_mutex：保护查询线程的更改
- trx_mutex：trx_t
- Search system mutex
- Buffer pool mutex
- Log mutex
- Memory pool mutex 

2. **rw_lock（sync0rw.h）**，读写操作的并发访问，在MySQL中主要就是针对Btree的并发访问，其中有两种锁粒度：index和block。而对于树结构的访问，如果只是读操作，那么，non-leaf节点只是用来查找leafnode，当找到之后，分支的lock可以释放了；而如果是写操作，只有需要节点分裂或者合并，那么整条路径都需要加xlock（当insert时，判断leafnode是否非满；当delete时，判断leafnode中记录数是否大于一半）。

- Secondary index tree latch ，Secondary index non-leaf 和 leaf的读写
- Clustered index tree latch，Clustered index non-leaf 和 leaf的读写
- Purge system latch，Undo log pages的读写，
- Filespace management latch，file page的读写
- 等等

### rw_lock

rw_lock基于如下结构实现的自旋锁。多个readthread可以持有一个s模式的rw_lock。但是，x模式的rw_lock只能被一个writethread持有；为了避免writethread被多个readthread饿死，writethread可以通过排队的方式阻塞新的readthread，每排队一个writethread将lockword减X_LOCK_DECR（新的SX锁等待时，减X_LOCK_HALF_DECR）。在wl6363中，标明了加了SX锁后lock_word不同取值的意思；其中lock_word=0表示加了xlock；lock_word= 0x20000000没有加锁；

```c
struct rw_lock_t
#ifdef UNIV_DEBUG
	: public latch_t
#endif /* UNIV_DEBUG */
{
	/** Holds the state of the lock. */
	volatile lint	lock_word;

	/** 1: there are waiters */
	volatile ulint	waiters;

	/** Default value FALSE which means the lock is non-recursive.
	The value is typically set to TRUE making normal rw_locks recursive.
	In case of asynchronous IO, when a non-zero value of 'pass' is
	passed then we keep the lock non-recursive.

	This flag also tells us about the state of writer_thread field.
	If this flag is set then writer_thread MUST contain the thread
	id of the current x-holder or wait-x thread.  This flag must be
	reset in x_unlock functions before incrementing the lock_word */
	volatile bool	recursive;

	/** number of granted SX locks. */
	volatile ulint	sx_recursive;

	/** This is TRUE if the writer field is RW_LOCK_X_WAIT; this field
	is located far from the memory update hotspot fields which are at
	the start of this struct, thus we can peek this field without
	causing much memory bus traffic */
	bool		writer_is_wait_ex;

	/** Thread id of writer thread. Is only guaranteed to have sane
	and non-stale value iff recursive flag is set. */
	volatile os_thread_id_t	writer_thread;

	/** Used by sync0arr.cc for thread queueing */
	os_event_t	event;

	/** Event for next-writer to wait on. A thread must decrement
	lock_word before waiting. */
	os_event_t	wait_ex_event;

	/** File name where lock created */
	const char*	cfile_name;

	/** last s-lock file/line is not guaranteed to be correct */
	const char*	last_s_file_name;

	/** File name where last x-locked */
	const char*	last_x_file_name;

	/** Line where created */
	unsigned	cline:13;

	/** If 1 then the rw-lock is a block lock */
	unsigned	is_block_lock:1;

	/** Line number where last time s-locked */
	unsigned	last_s_line:14;

	/** Line number where last time x-locked */
	unsigned	last_x_line:14;

	/** Count of os_waits. May not be accurate */
	uint32_t	count_os_wait;

	/** All allocated rw locks are put into a list */
	UT_LIST_NODE_T(rw_lock_t) list;

#ifdef UNIV_PFS_RWLOCK
	/** The instrumentation hook */
	struct PSI_rwlock*	pfs_psi;
#endif /* UNIV_PFS_RWLOCK */

#ifndef INNODB_RW_LOCKS_USE_ATOMICS
	/** The mutex protecting rw_lock_t */
	mutable ib_mutex_t mutex;
#endif /* INNODB_RW_LOCKS_USE_ATOMICS */

#ifdef UNIV_DEBUG
/** Value of rw_lock_t::magic_n */
# define RW_LOCK_MAGIC_N	22643

	/** Constructor */
	rw_lock_t()
	{
		magic_n = RW_LOCK_MAGIC_N;
	}

	/** Destructor */
	virtual ~rw_lock_t()
	{
		ut_ad(magic_n == RW_LOCK_MAGIC_N);
		magic_n = 0;
	}

	virtual std::string to_string() const;
	virtual std::string locked_from() const;

	/** For checking memory corruption. */
	ulint		magic_n;

	/** In the debug version: pointer to the debug info list of the lock */
	UT_LIST_BASE_NODE_T(rw_lock_debug_t) debug_list;

	/** Level in the global latching order. */
	latch_level_t	level;

#endif /* UNIV_DEBUG */

}
```



在5.7中，rw_lock共有四种类型，（在5.7新加了一个[SX](https://dev.mysql.com/worklog/task/?id=6363)类型）。

```c
enum rw_lock_type_t {
	RW_S_LATCH = 1,
	RW_X_LATCH = 2,
	RW_SX_LATCH = 4,
	RW_NO_LATCH = 8
};
/*
 LOCK COMPATIBILITY MATRIX
    S SX  X
 S  +  +  -
 SX +  -  -
 X  -  -  -
 */
```

这个新加的SX锁，从功能上可以由一个S锁加一个X锁代替。但是这样需要额外的原子操作，因此将两个整个为一个SX锁。当持有SX锁时，申请X锁需要'x-lock;sx-unlock;'。当持有X锁时，X锁可也降级为SX锁，而不需要'sx-lock；x-unlock'；。

在对Btree操作时，针对如下Btree的不同操作，对Btree的Index(内存dict_cache中的dict_index_t结构)或者Page(buf_pool->page)加不同模式的rw_lock。Btree有如下的基本操作模式，作为btr_cur_search_to_nth_level的参数latch_mode（无符号32位整型）的低字节；而高字节放一些标记位。

```c
/** Latching modes for btr_cur_search_to_nth_level(). */
enum btr_latch_mode {
	/** Search a record on a leaf page and S-latch it. */
	BTR_SEARCH_LEAF = RW_S_LATCH,
	/** (Prepare to) modify a record on a leaf page and X-latch it. */
	BTR_MODIFY_LEAF	= RW_X_LATCH,
	/** Obtain no latches. */
	BTR_NO_LATCHES = RW_NO_LATCH,
	/** Start modifying the entire B-tree. */
	BTR_MODIFY_TREE = 33,
	/** Continue modifying the entire B-tree. */
	BTR_CONT_MODIFY_TREE = 34,
	/** Search the previous record. */
	BTR_SEARCH_PREV = 35,
	/** Modify the previous record. */
	BTR_MODIFY_PREV = 36,
	/** Start searching the entire B-tree. */
	BTR_SEARCH_TREE = 37,
	/** Continue searching the entire B-tree. */
	BTR_CONT_SEARCH_TREE = 38
};
```



# 参考文章

[Undo漫游]([http://mysql.taobao.org/monthly/2015/04/01/](http://mysql.taobao.org/monthly/2015/04/01/))

[binlog文档](https://dev.mysql.com/doc/internals/en/binary-log-overview.html)

[worklog-mysql-5223](https://dev.mysql.com/worklog/task/?id=5223)

[binlog-group-commit]([http://mysqlmusings.blogspot.com/2012/06/binary-log-group-commit-in-mysql-56.html](http://mysqlmusings.blogspot.com/2012/06/binary-log-group-commit-in-mysql-56.html))











