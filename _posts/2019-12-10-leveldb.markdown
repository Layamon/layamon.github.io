---
layout: post
title: Database Storage Structure
date: 2019-12-10 11:21
categories:
  - LSM-tree
  - Database
typora-root-url: ../../yummyliu.github.io
---
* TOC
{:toc}
TransactionManager/LockManager/LogManager/AccessMethod are the four importance component in transactional storage engine. AccessMethod means the data organization, such as Btree/LSM-tree. 

Btree's appearance is based on HDD diskï¼›nowadays, there are more and more difference storage medium, so that the research of new access method is going on. In this article, I want to summarize my knowledge on this questionâ€”â€”Database AccessMethod. (My English is so poor, sorry for thatðŸ˜‚)

This article include three section, firstly, I introduce the RUM conjecture of access method. Secondly, I review the classic access methodâ€”â€”Btree. At last, I share my study on the new(no that new, it is came up in 1996) and popular access methodâ€”â€”LSM-tree. 

# RUM conjecture

> **RUM conjecture**
>
> *When designing access methods we set an upper bound for two of the RUM overheads, this implies a hard lower bound for the third overhead which cannot be further reduced*

![img](/image/1212-rum.png)

Like the CAP theory for distribution consensus, RUM conjecture is the triangle for access method. it mean that we can not have a perfect access method which satisfy Read Optimized/Update Optimized/MemoryOptimized. We can try our best to only satify two of the three with sacrificed the other one.

So, when we design a DB storage structure, there are three amplification we need to think(below picture).



![image-20191213172335893](/image/1212-storage.png)

To optimize write amplification, we can use differential data structure to consolidate many update into one I/O, and avoid the cost of data reorganization. but it slows down read and has space waste.

To optimize read amplificatioin, we can use special physical index for appropriate workload, but it brings the wirte and space waste since there are multiple data copies.

Based on this conjecture, we can rethink Btree and LSM-tree.

# Btree

Let's review the Btree. BTREE is self-**B**alancing **TREE**. Comparing to BST/AVL-tree/Red-Black-tree, it is a **disk** balance tree(summarize in under picture). 

![image-20191215101830900](/image/1212-BBB.png)

Generally, when we say Btree, we mean B+-tree. Assuming that table size is N, which means leafnodes has **N** records; We assume that the depth of B+-tree does not count leaflevel and one page has **B** record; so the depth of Btree is $log_{B}N/B$:

<=> $N = B^{depth+1}$

<=> $N/B = B^{depth}$

<=>$depth = log_{B}N/B$

It is smaller than BST, so that we can minimize that disk I/O counts.

Furthermore, when read a record of Btree, it needs to read all node in the path. So, read amplication of Btree equals to depth. And write a record in leafnode, it needs to write out the whole page, so write amplificatioin of Btree is B. However, doing an insert into btree with bufferpool can return without IO, but bufferpool maybe miss that need an extra IO to load page.

Btree is used in all tranditional DBMS, like InnoDB, PostgreSQL. Now, there are many special storage engine, like LevelDB/RocksDB. It use a different structureâ€”â€”LSM-tree, which claims that has better write performance than Btree and with no so bad read performance. Let's check it out.

# LSM-tree

LSM-tree(Log Struct Merge tree) is a concept rather than a concrete structure. The log concept is borrowed from Log Structured File System, not from database write ahead log. Tree in LSM-tree can be replaced by other sorted structure. So, the nut of LSM-tree is Merge. LSM tree takes full advantage of multi-level storage to buffer writes, so that it has good write performance.

> In a word, LSM-tree sum up as:
>
> Log is borrowed, Tree can be replaced, Merge is the king.

Therefore, understanding how merge is done is the key to understand LSM-tree. 

LSM-tree is compose of two or more tree-like components, which distribute from small, expensive and higher performing medium to larger, cheap and lower performance medium. Like under picture in the paper.

![image-20191216110957361](/image/1212-level.png)

Since LSM-tree is a concept not a concrete implement, there are many different implement, like levelDB, RocksDB,Cassandra. In this article, I will walk through the LevelDB implement to explain LSM-tree.

![image-20191216103816910](/image/1212-leveldb.png)

When **write** a `(k,v)` into LevelDB, firstly, insert a log record; Then, insert into MemTable which is a sorted structure in memory, and write requesy is done. So, we can see that **write in LevelDB is effective than Btree**. 

But `(k,v)` data is not write into disk, it remain for compaction process to merge it into SSTable in disk. Compaction process compose of two main process, sorting and garbage collection, and has two different trigger strategy.

+ Sized-tiered Compaction Strategy, each level has N sorted runs (overlapped). Compaction merges all sorted runs in one level to create a new sorted run in the next level. This strategy minimizes write amplification at the cost of read and space amplification.

+ Level-based compaction strategy, each level is one sorted run. Compaction into $L_n$ merges data from $L_n-1$ into $L_n$. Compaction into $L_n$ rewrites data that was previously merged into $L_n$.   This strategy minimizes space amplification and read amplification at the cost of write amplification.

But in LevelDB, it is an combination of tiered and level. Furthermore, LevelDB add an partition optimization(dispart each level tree into range pieces). So the hold merge flow is in under picture. It need to know that new merged block is written to new disk position, so that the old block can be used in recovery. 

![image-20191216114802822](/image/1212-leveldb-compact.png)

Like vacuum process in PostgreSQL, It needs to know that compaction rate is a problem, too fast bring write amplification, too slow bring read amplification and space amplification.

Since data can exist in any level in levelDB, when do a `get(k)`, we first search MemTable, then Immutable MemTable, and level-0, level-1 and so on.  So **read in LSM-tree is not as best as Btree**. But we can use cache and (Bloom) filter to decrease I/Os in read.

The same as Btree, we assume database table has  N records, means that the last level has N recordsã€‚it assume that we have $d$ levels, the first level has B record and every compaction has growth factorâ€”â€”k, so that depth of LSM-tree is $log_{k}^{N/B}$.

<=>$B*k^d = N$

<=>$d=log_{k}^{N/B}$

> More precisely, there are quantitative compare between Btree and LSM-tree.
>
> | Data Structure       | Write Amplification | Read Amplification |
> | -------------------- | ------------------- | ------------------ |
> | B+ tree              | Î˜($B$)              | $O(log_{B}N/B)$    |
> | Level-Based LSM-tree | Î˜($klog_{k}{N/B}$)  | Î˜((log^2N/B)/logk) |
>
>  Reference From [deep dive tikv](https://tikv.github.io/deep-dive-tikv/key-value-engine/B-Tree-vs-Log-Structured-Merge-Tree.html)

As far as I know, optimization of LSM-tree concentrate on two points:

+ Use filter to decrease read IOs. 
  + bloom filter optimize read IOï¼Œbut only work in point queryï¼Œ
  + Prefix bloom filter that work for `like %`.
  + Succinct Range Filter which like a trie.
  + Cuckoo Filter...
+ Compaction optimization:
  + pipelined compaction, try best to make every procedure in pipeline cost similar time, but in multi-core sys, may result in low CPU cache performance.
  + FPGA for sorting calculate.
  + Wisckey: separate key and value, key use for sorting, value use for garbage collection.

This a rough summary of Btree and LSM-tree, hope it can help you. there are some interesting links:

[lsm1](https://www.slideshare.net/ssuser7e134a/log-structured-merge-tree)

[tikv](https://tikv.github.io/deep-dive-tikv/key-value-engine/B-Tree-vs-Log-Structured-Merge-Tree.html)

[btree and lsm](https://av.tib.eu/media/42855)

[btree and lsm 2](http://smalldatum.blogspot.com/2015/11/read-write-space-amplification-b-tree.html)

[lsm2](https://medium.com/databasss/on-disk-io-part-3-lsm-trees-8b2da218496f)